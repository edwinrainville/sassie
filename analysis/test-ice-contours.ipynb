{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c24108d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cartopy\n",
    "import cv2\n",
    "import cmocean\n",
    "import cftime\n",
    "from datetime import datetime, timedelta\n",
    "import numpy as np\n",
    "import netCDF4 as nc\n",
    "import pandas as pd\n",
    "import pyproj as proj\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.colors\n",
    "import matplotlib.dates as mdates\n",
    "import metpy.calc as mpcalc\n",
    "from scipy import io, interpolate, stats, signal\n",
    "from scipy.optimize import curve_fit\n",
    "from scipy.spatial import cKDTree\n",
    "\n",
    "%matplotlib widget"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d74306e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Helping Functions\n",
    "def datenum_to_datetime(datenum):\n",
    "    \"\"\"\n",
    "    Convert Matlab datenum into Python datetime.\n",
    "    :param datenum: Date in datenum format\n",
    "    :return:        Datetime object corresponding to datenum.\n",
    "    \"\"\"\n",
    "    days = datenum % 1\n",
    "    return datetime.fromordinal(int(datenum)) \\\n",
    "           + timedelta(days=days) \\\n",
    "           - timedelta(days=366)\n",
    "\n",
    "def latlon_to_local(lat, lon, lat_0, lon_0):\n",
    "    crs_wgs = proj.Proj(init='epsg:4326')  # assuming you're using WGS84 geographic\n",
    "\n",
    "    #Erect own local flat cartesian coordinate system\n",
    "    cust = proj.Proj(\"+proj=aeqd +lat_0={0} +lon_0={1} +datum=WGS84 +units=m\".format(lat_0, lon_0))\n",
    "    x, y = proj.transform(crs_wgs, cust, lon, lat)\n",
    "    return x, y\n",
    "\n",
    "\n",
    "def local_to_latlon(x, y, lat_0, lon_0):\n",
    "    # Define projections\n",
    "    crs_wgs = proj.Proj(init='epsg:4326')  # WGS84 geographic\n",
    "    cust = proj.Proj(\"+proj=aeqd +lat_0={0} +lon_0={1} +datum=WGS84 +units=m\".format(lat_0, lon_0))\n",
    "\n",
    "    # Transform from local AEQD projection back to geographic\n",
    "    lon, lat = proj.transform(cust, crs_wgs, x, y)\n",
    "    return lat, lon\n",
    "\n",
    "def binned_statistics(x, y, bins=10, statistic='median'):\n",
    "    \"\"\"\n",
    "    Bins the x variable into specified intervals, calculates the specified statistic (mean or median)\n",
    "    of y values within each bin, and returns the statistic values, the bin centers, and the number\n",
    "    of data points in each bin.\n",
    "\n",
    "    Parameters:\n",
    "    - x: array-like, continuous numerical variable to bin\n",
    "    - y: array-like, continuous numerical variable for which the statistic is calculated within each bin\n",
    "    - bins: int, the number of bins to create for the x variable\n",
    "    - statistic: str, 'mean' or 'median' to specify which statistic to calculate\n",
    "\n",
    "    Returns:\n",
    "    - bin_centers: array, the center value of each bin\n",
    "    - statistics: array, the calculated statistic (mean or median) for y values within each bin\n",
    "    - counts: array, the number of data points in each bin\n",
    "    \"\"\"\n",
    "    \n",
    "    # Validate the statistic parameter\n",
    "    if statistic not in ['mean', 'median', 'variance']:\n",
    "        raise ValueError(\"Statistic must be 'mean', 'median', or 'variance'.\")\n",
    "\n",
    "    # Create bins\n",
    "    bin_edges = np.linspace(np.min(x), np.max(x), bins + 1)\n",
    "    binned_indices = np.digitize(x, bins=bin_edges)\n",
    "\n",
    "    # Calculate the bin centers\n",
    "    bin_centers = (bin_edges[:-1] + bin_edges[1:]) / 2\n",
    "\n",
    "    # Calculate the specified statistic for each bin\n",
    "    if statistic == 'mean':\n",
    "        statistics = [np.nanmean(y[binned_indices == i]) for i in range(1, bins + 1)]\n",
    "    elif statistic == 'median':\n",
    "        statistics = [np.nanmedian(y[binned_indices == i]) for i in range(1, bins + 1)]\n",
    "    elif statistic == 'variance':\n",
    "        statistics = [np.nanvar(y[binned_indices == i]) for i in range(1, bins + 1)]\n",
    "    \n",
    "    # Compute std for each bin\n",
    "    std_in_bin = [np.nanstd(y[binned_indices == i]) for i in range(1, bins + 1)]\n",
    "\n",
    "    # Check Normal Distribution Goodness of Fit Test for each bin\n",
    "    \n",
    "    # Remove NaN values from the \n",
    "\n",
    "    # Count the number of data points for each bin\n",
    "    counts = [np.sum(binned_indices == i) for i in range(1, bins + 1)]\n",
    "\n",
    "    return np.array(bin_centers), np.array(statistics), np.array(counts), np.array(std_in_bin)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29e10a33",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add the wave gliders back in\n",
    "df = pd.read_csv('../data/play1_df.csv')\n",
    "df = df.dropna(subset=['hs'])\n",
    "df.head()\n",
    "\n",
    "# Load the Gridded Ice Maps\n",
    "ice_map_data = io.loadmat('../data/L1/nws_2022.mat')\n",
    "ice_map_lat = ice_map_data['LAT']\n",
    "ice_map_lon = ice_map_data['LON']\n",
    "ice_map_conc = ice_map_data['iceconc'] * 10\n",
    "ice_map_datenum = np.squeeze(ice_map_data['date'])\n",
    "ice_map_date = [datenum_to_datetime(ice_map_datenum[n].astype(np.float64)) for n in range(ice_map_datenum.size)]\n",
    "\n",
    "# Find index of closest Ice Map - September 10th \n",
    "ind_for_ice_map = 252\n",
    "print(ice_map_date[ind_for_ice_map])\n",
    "ice_concentration = ice_map_conc[:,:,ind_for_ice_map]\n",
    "\n",
    "# Compute Ice Edge Based on 80% Concentration\n",
    "ice_conc_80percent = np.zeros(ice_concentration.shape)\n",
    "ice_conc_80percent[ice_concentration >= 80] = 1\n",
    "\n",
    "# Compute Ice Edge Based on 15% Concentration\n",
    "ice_conc_15percent = np.zeros(ice_concentration.shape)\n",
    "ice_conc_15percent[ice_concentration >= 15] = 1\n",
    "\n",
    "# Compute Ice Edge Based on 0% Concentration\n",
    "ice_conc_1percent = np.zeros(ice_concentration.shape)\n",
    "ice_conc_1percent[ice_concentration >= 1] = 1\n",
    "\n",
    "# Define the Local Cartesian Coordinate System\n",
    "lat_0 = 72.48\n",
    "lon_0 = -151.1\n",
    "\n",
    "# Convert Lat lon on Ice Map to cartesian system \n",
    "x_icemap, y_icemap = latlon_to_local(ice_map_lat, ice_map_lon, lat_0, lon_0)\n",
    "\n",
    "# Convert the SWIFT Track Coordinates to the local Cartesian system\n",
    "x_swifts_gliders, y_swifts_gliders = latlon_to_local(df['latitude'], df['longitude'], lat_0, lon_0)\n",
    "\n",
    "# Get time values for the SWIFTs\n",
    "time_swifts = df['time'][:]\n",
    "datetimes = pd.to_datetime(time_swifts)\n",
    "date_numbers = np.squeeze(mdates.date2num(datetimes))\n",
    "\n",
    "# Find the x and y location of the 15% ice concentration\n",
    "# Find the 15% concentration contour line\n",
    "ice_edge_contour_lon_vals = ice_map_lon[:,0]\n",
    "lat_vals = ice_map_lat[0,:]\n",
    "\n",
    "ice_edge_80percent_contour_lat_vals = []\n",
    "ice_edge_15percent_contour_lat_vals = []\n",
    "ice_edge_1percent_contour_lat_vals = []\n",
    "\n",
    "for n in range(ice_conc_15percent.shape[0]):\n",
    "    # 1% contour\n",
    "    ice_edge_lat_index_array = np.where(ice_conc_1percent[n,:] == 1)[0]\n",
    "    if ice_edge_lat_index_array.size > 0:\n",
    "        ice_edge_1percent_contour_lat_vals.append(lat_vals[ice_edge_lat_index_array[0]])\n",
    "    else:\n",
    "        ice_edge_1percent_contour_lat_vals.append(np.NaN)\n",
    "        \n",
    "    # 15% contour\n",
    "    ice_edge_lat_index_array = np.where(ice_conc_15percent[n,:] == 1)[0]\n",
    "    if ice_edge_lat_index_array.size > 0:\n",
    "        ice_edge_15percent_contour_lat_vals.append(lat_vals[ice_edge_lat_index_array[0]])\n",
    "    else:\n",
    "        ice_edge_15percent_contour_lat_vals.append(np.NaN)\n",
    "\n",
    "    # 80% contour\n",
    "    ice_edge_lat_index_array = np.where(ice_conc_80percent[n,:] == 1)[0]\n",
    "    if ice_edge_lat_index_array.size > 0:\n",
    "        ice_edge_80percent_contour_lat_vals.append(lat_vals[ice_edge_lat_index_array[0]])\n",
    "    else:\n",
    "        ice_edge_80percent_contour_lat_vals.append(np.NaN)\n",
    "\n",
    "# Convert lon values to numpy array\n",
    "ice_edge_80percent_contour_lat_vals = np.array(ice_edge_80percent_contour_lat_vals)\n",
    "ice_edge_15percent_contour_lat_vals = np.array(ice_edge_15percent_contour_lat_vals)\n",
    "ice_edge_1percent_contour_lat_vals = np.array(ice_edge_1percent_contour_lat_vals)\n",
    "\n",
    "\n",
    "def smooth_ice_contour(lat_vals, lon_vals, lat_0, lon_0):\n",
    "    # Convert the ice edge values to cartesian and polar coordinates\n",
    "    x_iceedge, y_iceedge = latlon_to_local(lat_vals, lon_vals, lat_0, lon_0)\n",
    "\n",
    "    # Interpolate the x and y ice edge values to make a smooth curve of the ice edge\n",
    "    x_iceedge_interp = np.linspace(-100000, 200000, num=50000)\n",
    "    y_iceedge_interp = np.interp(x_iceedge_interp, x_iceedge, y_iceedge)\n",
    "\n",
    "    fs = 1 / (x_iceedge_interp[1] - x_iceedge_interp[0])\n",
    "    cutoff = 1/40000\n",
    "    order = 1\n",
    "    nyq = 0.5 * fs\n",
    "    normal_cutoff = cutoff / nyq\n",
    "    b, a = signal.butter(order, normal_cutoff, btype='low', analog=False)\n",
    "    y_iceedge_smoothed = signal.filtfilt(b, a, y_iceedge_interp)\n",
    "\n",
    "    return x_iceedge_interp, y_iceedge_smoothed\n",
    "\n",
    "# Smooth the ice concentration contours\n",
    "x_80percent_contour, y_80percent_contour = smooth_ice_contour(ice_edge_80percent_contour_lat_vals, ice_edge_contour_lon_vals, lat_0, lon_0)\n",
    "x_15percent_contour, y_15percent_contour = smooth_ice_contour(ice_edge_15percent_contour_lat_vals, ice_edge_contour_lon_vals, lat_0, lon_0)\n",
    "x_1percent_contour, y_1percent_contour = smooth_ice_contour(ice_edge_1percent_contour_lat_vals, ice_edge_contour_lon_vals, lat_0, lon_0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "83453db3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute the Cross Ice and Along Ice Coordinates for each point\n",
    "def compute_cross_ice_distance(point_x, point_y, ice_x, ice_y):\n",
    "    \"\"\"\n",
    "    Computes the signed normal (perpendicular) distance of an array of points from the ice edge defined by two arrays of x and y coordinates.\n",
    "    The distance is negative if the ice edge is above the point (ice_y > point_y).\n",
    "    \n",
    "    Parameters:\n",
    "        point_x (array-like): An array of x coordinates for the points.\n",
    "        point_y (array-like): An array of y coordinates for the points.\n",
    "        ice_x (array-like): An array of x coordinates defining the ice edge.\n",
    "        ice_y (array-like): An array of y coordinates defining the ice edge.\n",
    "    \n",
    "    Returns:\n",
    "        numpy.ndarray: An array of signed distances corresponding to each point.\n",
    "    \"\"\"\n",
    "    points = np.column_stack((point_x, point_y))\n",
    "    ice_points = np.column_stack((ice_x, ice_y))\n",
    "    \n",
    "    # Use KDTree to find the closest point on the ice edge\n",
    "    tree = cKDTree(ice_points)\n",
    "    distances, indices = tree.query(points)\n",
    "    \n",
    "    # Determine the sign of the distance based on the y-coordinate comparison\n",
    "    signed_distances = np.where(ice_y[indices] > point_y, -distances, distances)\n",
    "    \n",
    "    return signed_distances, indices\n",
    "\n",
    "cross_ice_distance_initial, indices = compute_cross_ice_distance(x_swifts_gliders, y_swifts_gliders, x_1percent_contour, y_1percent_contour)\n",
    "\n",
    "fig, ax = plt.subplots()\n",
    "ax.scatter(datetimes, cross_ice_distance_initial)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "sassie-env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
